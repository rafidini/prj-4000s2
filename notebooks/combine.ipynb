{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arranged-cherry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:18.595640Z",
     "start_time": "2021-03-23T15:43:15.657130Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "from cv2 import imread\n",
    "from cv2 import IMREAD_COLOR\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verbal-third",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:20.094406Z",
     "start_time": "2021-03-23T15:43:18.596637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Neural/conv & Co networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from string import punctuation\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "corrected-algorithm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:20.110004Z",
     "start_time": "2021-03-23T15:43:20.095077Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-minutes",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:20.125963Z",
     "start_time": "2021-03-23T15:43:20.110998Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "checked-siemens",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:21.736628Z",
     "start_time": "2021-03-23T15:43:20.126955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7704376036267331634\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4963368960\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5461297678523710374\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "established-invalid",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:21.752586Z",
     "start_time": "2021-03-23T15:43:21.737626Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            #tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solar-graphic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:23.548822Z",
     "start_time": "2021-03-23T15:43:21.754581Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>color_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sankyo aluminum shade beam standing type one s...</td>\n",
       "      <td>278003_10389968_1.jpg</td>\n",
       "      <td>['Silver', 'Grey', 'Black']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sale sale fashion coordination thick sash belt...</td>\n",
       "      <td>220810_10010506_1.jpg</td>\n",
       "      <td>['Brown', 'Black']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geta paulownia made japan woman tone nose widt...</td>\n",
       "      <td>207456_10045549_1.jpg</td>\n",
       "      <td>['White', 'Black']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limited time yen coupon issuance shoe box widt...</td>\n",
       "      <td>346541_10000214_1.jpg</td>\n",
       "      <td>['Beige', 'Brown', 'Black']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post mailbox mailbox post multi family housing...</td>\n",
       "      <td>240426_10024071_1.jpg</td>\n",
       "      <td>['Silver']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    item_description        image_file_name  \\\n",
       "0  sankyo aluminum shade beam standing type one s...  278003_10389968_1.jpg   \n",
       "1  sale sale fashion coordination thick sash belt...  220810_10010506_1.jpg   \n",
       "2  geta paulownia made japan woman tone nose widt...  207456_10045549_1.jpg   \n",
       "3  limited time yen coupon issuance shoe box widt...  346541_10000214_1.jpg   \n",
       "4  post mailbox mailbox post multi family housing...  240426_10024071_1.jpg   \n",
       "\n",
       "                    color_tags  \n",
       "0  ['Silver', 'Grey', 'Black']  \n",
       "1           ['Brown', 'Black']  \n",
       "2           ['White', 'Black']  \n",
       "3  ['Beige', 'Brown', 'Black']  \n",
       "4                   ['Silver']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_clean.csv\")\n",
    "df[\"color_tags\"] = pd.read_csv(\"y_train.csv\")[\"color_tags\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acknowledged-uzbekistan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:23.594699Z",
     "start_time": "2021-03-23T15:43:23.550817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>color_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>NaN</td>\n",
       "      <td>284861_10152178_1.gif</td>\n",
       "      <td>['Blue']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196161</th>\n",
       "      <td>NaN</td>\n",
       "      <td>284861_10152142_1.gif</td>\n",
       "      <td>['Blue']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_description        image_file_name color_tags\n",
       "4172                NaN  284861_10152178_1.gif   ['Blue']\n",
       "196161              NaN  284861_10152142_1.gif   ['Blue']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trained-switzerland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:24.000615Z",
     "start_time": "2021-03-23T15:43:23.595697Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"color_tags\"] = df[\"color_tags\"].apply(lambda x: x[1:-1].replace(\"'\",\"\").split(','))\n",
    "unique_colors = set()\n",
    "for line in df[\"color_tags\"]:\n",
    "    for color in line:\n",
    "        unique_colors.add(color)\n",
    "        \n",
    "df[\"image_file_name\"] = df[\"image_file_name\"].apply(lambda x: \"./images/\"+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "young-nitrogen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:24.015575Z",
     "start_time": "2021-03-23T15:43:24.001613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>color_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sankyo aluminum shade beam standing type one s...</td>\n",
       "      <td>./images/278003_10389968_1.jpg</td>\n",
       "      <td>[Silver,  Grey,  Black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sale sale fashion coordination thick sash belt...</td>\n",
       "      <td>./images/220810_10010506_1.jpg</td>\n",
       "      <td>[Brown,  Black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geta paulownia made japan woman tone nose widt...</td>\n",
       "      <td>./images/207456_10045549_1.jpg</td>\n",
       "      <td>[White,  Black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limited time yen coupon issuance shoe box widt...</td>\n",
       "      <td>./images/346541_10000214_1.jpg</td>\n",
       "      <td>[Beige,  Brown,  Black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post mailbox mailbox post multi family housing...</td>\n",
       "      <td>./images/240426_10024071_1.jpg</td>\n",
       "      <td>[Silver]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    item_description  \\\n",
       "0  sankyo aluminum shade beam standing type one s...   \n",
       "1  sale sale fashion coordination thick sash belt...   \n",
       "2  geta paulownia made japan woman tone nose widt...   \n",
       "3  limited time yen coupon issuance shoe box widt...   \n",
       "4  post mailbox mailbox post multi family housing...   \n",
       "\n",
       "                  image_file_name               color_tags  \n",
       "0  ./images/278003_10389968_1.jpg  [Silver,  Grey,  Black]  \n",
       "1  ./images/220810_10010506_1.jpg          [Brown,  Black]  \n",
       "2  ./images/207456_10045549_1.jpg          [White,  Black]  \n",
       "3  ./images/346541_10000214_1.jpg  [Beige,  Brown,  Black]  \n",
       "4  ./images/240426_10024071_1.jpg                 [Silver]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "overhead-broadcasting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:24.141240Z",
     "start_time": "2021-03-23T15:43:24.016573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "MAX_SEQUENCE_LENGTH = df['item_description'].map(len).max()\n",
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circular-bicycle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:44.968776Z",
     "start_time": "2021-03-23T15:43:24.142237Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False)\n",
    "tokenizer.fit_on_texts(df['item_description'])\n",
    "word_index = tokenizer.word_index\n",
    "df['tokenized_items'] = tokenizer.texts_to_sequences(df['item_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "considered-border",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:44.984441Z",
     "start_time": "2021-03-23T15:43:44.969318Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>color_tags</th>\n",
       "      <th>tokenized_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sankyo aluminum shade beam standing type one s...</td>\n",
       "      <td>./images/278003_10389968_1.jpg</td>\n",
       "      <td>[Silver,  Grey,  Black]</td>\n",
       "      <td>[4396, 619, 962, 2506, 2388, 17, 31, 772, 382,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sale sale fashion coordination thick sash belt...</td>\n",
       "      <td>./images/220810_10010506_1.jpg</td>\n",
       "      <td>[Brown,  Black]</td>\n",
       "      <td>[162, 162, 207, 775, 530, 1482, 377, 1482, 377...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geta paulownia made japan woman tone nose widt...</td>\n",
       "      <td>./images/207456_10045549_1.jpg</td>\n",
       "      <td>[White,  Black]</td>\n",
       "      <td>[4459, 2282, 24, 88, 50, 878, 1885, 10, 211, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limited time yen coupon issuance shoe box widt...</td>\n",
       "      <td>./images/346541_10000214_1.jpg</td>\n",
       "      <td>[Beige,  Brown,  Black]</td>\n",
       "      <td>[453, 16, 72, 779, 9629, 105, 166, 10, 140, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post mailbox mailbox post multi family housing...</td>\n",
       "      <td>./images/240426_10024071_1.jpg</td>\n",
       "      <td>[Silver]</td>\n",
       "      <td>[698, 3116, 3116, 698, 557, 799, 3487, 7328, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    item_description  \\\n",
       "0  sankyo aluminum shade beam standing type one s...   \n",
       "1  sale sale fashion coordination thick sash belt...   \n",
       "2  geta paulownia made japan woman tone nose widt...   \n",
       "3  limited time yen coupon issuance shoe box widt...   \n",
       "4  post mailbox mailbox post multi family housing...   \n",
       "\n",
       "                  image_file_name               color_tags  \\\n",
       "0  ./images/278003_10389968_1.jpg  [Silver,  Grey,  Black]   \n",
       "1  ./images/220810_10010506_1.jpg          [Brown,  Black]   \n",
       "2  ./images/207456_10045549_1.jpg          [White,  Black]   \n",
       "3  ./images/346541_10000214_1.jpg  [Beige,  Brown,  Black]   \n",
       "4  ./images/240426_10024071_1.jpg                 [Silver]   \n",
       "\n",
       "                                     tokenized_items  \n",
       "0  [4396, 619, 962, 2506, 2388, 17, 31, 772, 382,...  \n",
       "1  [162, 162, 207, 775, 530, 1482, 377, 1482, 377...  \n",
       "2  [4459, 2282, 24, 88, 50, 878, 1885, 10, 211, 1...  \n",
       "3  [453, 16, 72, 779, 9629, 105, 166, 10, 140, 61...  \n",
       "4  [698, 3116, 3116, 698, 557, 799, 3487, 7328, 2...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "increased-incentive",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.733968Z",
     "start_time": "2021-03-23T15:43:44.985439Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequence = pad_sequences(df[\"tokenized_items\"])  \n",
    "df_tmp=pd.DataFrame(sequence)\n",
    "s = df_tmp.apply(lambda row: row.to_list(),axis=1)\n",
    "df[\"sequences\"] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "brazilian-donor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.781846Z",
     "start_time": "2021-03-23T15:43:54.734968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE = len(sequence[0])\n",
    "MAX_SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pursuant-spouse",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.812764Z",
     "start_time": "2021-03-23T15:43:54.782844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_description</th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>color_tags</th>\n",
       "      <th>tokenized_items</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sankyo aluminum shade beam standing type one s...</td>\n",
       "      <td>./images/278003_10389968_1.jpg</td>\n",
       "      <td>[Silver,  Grey,  Black]</td>\n",
       "      <td>[4396, 619, 962, 2506, 2388, 17, 31, 772, 382,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sale sale fashion coordination thick sash belt...</td>\n",
       "      <td>./images/220810_10010506_1.jpg</td>\n",
       "      <td>[Brown,  Black]</td>\n",
       "      <td>[162, 162, 207, 775, 530, 1482, 377, 1482, 377...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geta paulownia made japan woman tone nose widt...</td>\n",
       "      <td>./images/207456_10045549_1.jpg</td>\n",
       "      <td>[White,  Black]</td>\n",
       "      <td>[4459, 2282, 24, 88, 50, 878, 1885, 10, 211, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>limited time yen coupon issuance shoe box widt...</td>\n",
       "      <td>./images/346541_10000214_1.jpg</td>\n",
       "      <td>[Beige,  Brown,  Black]</td>\n",
       "      <td>[453, 16, 72, 779, 9629, 105, 166, 10, 140, 61...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>post mailbox mailbox post multi family housing...</td>\n",
       "      <td>./images/240426_10024071_1.jpg</td>\n",
       "      <td>[Silver]</td>\n",
       "      <td>[698, 3116, 3116, 698, 557, 799, 3487, 7328, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    item_description  \\\n",
       "0  sankyo aluminum shade beam standing type one s...   \n",
       "1  sale sale fashion coordination thick sash belt...   \n",
       "2  geta paulownia made japan woman tone nose widt...   \n",
       "3  limited time yen coupon issuance shoe box widt...   \n",
       "4  post mailbox mailbox post multi family housing...   \n",
       "\n",
       "                  image_file_name               color_tags  \\\n",
       "0  ./images/278003_10389968_1.jpg  [Silver,  Grey,  Black]   \n",
       "1  ./images/220810_10010506_1.jpg          [Brown,  Black]   \n",
       "2  ./images/207456_10045549_1.jpg          [White,  Black]   \n",
       "3  ./images/346541_10000214_1.jpg  [Beige,  Brown,  Black]   \n",
       "4  ./images/240426_10024071_1.jpg                 [Silver]   \n",
       "\n",
       "                                     tokenized_items  \\\n",
       "0  [4396, 619, 962, 2506, 2388, 17, 31, 772, 382,...   \n",
       "1  [162, 162, 207, 775, 530, 1482, 377, 1482, 377...   \n",
       "2  [4459, 2282, 24, 88, 50, 878, 1885, 10, 211, 1...   \n",
       "3  [453, 16, 72, 779, 9629, 105, 166, 10, 140, 61...   \n",
       "4  [698, 3116, 3116, 698, 557, 799, 3487, 7328, 2...   \n",
       "\n",
       "                                           sequences  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ready-memorabilia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.906043Z",
     "start_time": "2021-03-23T15:43:54.813761Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169694, 2)\n",
      "(42424, 2)\n",
      "\n",
      "(169694,)\n",
      "(42424,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[[\"image_file_name\",\"sequences\"]],df[\"color_tags\"], test_size=0.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print()\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "magnetic-turkish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.922000Z",
     "start_time": "2021-03-23T15:43:54.907041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file_name</th>\n",
       "      <th>sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85035</th>\n",
       "      <td>./images/296970_10506152_1.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93012</th>\n",
       "      <td>./images/252082_10067475_1.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122258</th>\n",
       "      <td>./images/295152_21491524_1.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128746</th>\n",
       "      <td>./images/210806_10022238_1.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155869</th>\n",
       "      <td>./images/354562_10086498_1.jpg</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_file_name  \\\n",
       "85035   ./images/296970_10506152_1.jpg   \n",
       "93012   ./images/252082_10067475_1.jpg   \n",
       "122258  ./images/295152_21491524_1.jpg   \n",
       "128746  ./images/210806_10022238_1.jpg   \n",
       "155869  ./images/354562_10086498_1.jpg   \n",
       "\n",
       "                                                sequences  \n",
       "85035   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "93012   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "122258  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "128746  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "155869  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extreme-three",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:43:54.937937Z",
     "start_time": "2021-03-23T15:43:54.922998Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "class Custom_Generator(keras.utils.Sequence) :\n",
    "    \n",
    "    def __init__(self, data, labels, batch_size, size_image=-1):\n",
    "        self.image = data.iloc[:,0]\n",
    "        self.text = data.iloc[:,1]\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.size = size_image\n",
    "        self.encoder = LabelBinarizer().fit(list(unique_colors))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (np.ceil(len(self.labels) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    def open_gif(self,image):\n",
    "        gif = cv.VideoCapture(image)\n",
    "        ret, frame = gif.read()\n",
    "        cv.destroyAllWindows()\n",
    "        return frame\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_image = self.image[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_text = self.text[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for image in batch_image:\n",
    "            if not size==-1 :\n",
    "                if \".gif\" in image : image = resize(self.open_gif(image),size)\n",
    "                else : image = resize(imread(image,IMREAD_COLOR),size)\n",
    "            else : \n",
    "                if \".gif\" in image : image = self.open_gif(image)\n",
    "                else : image = imread(image,IMREAD_COLOR)\n",
    "\n",
    "            image = image/255.0\n",
    "            images.append(image)\n",
    "            \n",
    "        for y in batch_y:\n",
    "            labels.append( np.sum( self.encoder.transform(y), axis=0 ) )\n",
    "            \n",
    "        images = np.asarray(images)\n",
    "        texts = np.asarray(batch_text)\n",
    "        labels = np.asarray(labels)\n",
    "        \n",
    "        return [images,texts], labels, [None]\n",
    "    \n",
    "batch_size = 2\n",
    "size = (75, 115, 3)\n",
    "\n",
    "gen_train = Custom_Generator(X_train, y_train, batch_size, size)\n",
    "gen_test = Custom_Generator(X_test, y_test, batch_size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dense-lemon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:44:17.331931Z",
     "start_time": "2021-03-23T15:43:54.938935Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "def get_embedding_matrix(typeToLoad):\n",
    "    if typeToLoad == \"glove\":\n",
    "        EMBEDDING_FILE=\"/content/glove.twitter.27B.100d.txt\"\n",
    "        embed_size = 100\n",
    "    elif typeToLoad == \"word2vec\":\n",
    "        word2vecDict = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "        embed_size = 300\n",
    "    elif typeToLoad == \"fasttext\":\n",
    "        EMBEDDING_FILE=\"/content/wiki-news-300d-1M.vec\"\n",
    "        embed_size = 300\n",
    "\n",
    "    if typeToLoad == \"glove\" or typeToLoad == \"fasttext\":\n",
    "        embeddings_index = dict()\n",
    "        f = open(EMBEDDING_FILE)\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        f.close()\n",
    "        print(\"Loaded \" + str(len(embeddings_index)) + \" word vectors.\")\n",
    "    else:\n",
    "        embeddings_index = dict()\n",
    "        for word in word2vecDict.wv.vocab:\n",
    "            embeddings_index[word] = word2vecDict.word_vec(word)\n",
    "        print(\"Loaded \" + str(len(embeddings_index)) + \" word vectors.\")\n",
    "\n",
    "        embedding_matrix = 1 * np.random.randn(len(word_index)+1, embed_size)\n",
    "\n",
    "        embeddedCount = 0\n",
    "    for word, i in word_index.items():\n",
    "        i-=1\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            embeddedCount+=1\n",
    "        print(\"total embedded:\", embeddedCount, \"common words\")\n",
    "\n",
    "    del(embeddings_index)\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "word2vec_embedding_matrix = get_embedding_matrix(\"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "talented-province",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:44:17.362211Z",
     "start_time": "2021-03-23T15:44:17.332928Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Input, Bidirectional, Flatten, Conv2D, MaxPooling2D, concatenate, Conv1D, MaxPooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "searching-visiting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:44:17.378169Z",
     "start_time": "2021-03-23T15:44:17.363225Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(embedding_matrix):\n",
    "    lstm_input = Input(shape=(batch_size,))\n",
    "    x = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], mask_zero=True, input_length=MAX_SEQUENCE_LENGTH, trainable=False)(lstm_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(64, return_sequences = True)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    lstm_out = Dense(18, activation = 'relu')(x)\n",
    "\n",
    "    print(size[0], size[1], size[2])\n",
    "    cnn_input = Input(shape=(size[0], size[1], size[2]))\n",
    "    y = Conv2D(32, (3, 3), activation='relu', input_shape=(size[0], size[1], size[2]))(cnn_input)\n",
    "    y = MaxPooling2D(2, 2)(y)\n",
    "    y = Conv2D(64, (3, 3), activation='relu')(y)\n",
    "    y = MaxPooling2D(2, 2)(y)\n",
    "    y = Conv2D(128, (3, 3), activation='relu')(y)\n",
    "    y = MaxPooling2D(2, 2)(y)\n",
    "    y = Conv2D(128, (3, 3), activation='relu')(y)\n",
    "    y = MaxPooling2D(2, 2)(y)\n",
    "    y = Flatten()(y)\n",
    "    y = Dropout(0.3)(y)\n",
    "    cnn_out = Dense(512, activation='relu')(y)\n",
    "\n",
    "    concat_inp = concatenate([cnn_out, lstm_out])\n",
    "    z = Dense(256, activation='relu')(concat_inp)\n",
    "    z = Dropout(0.3)(z)\n",
    "    z = Dense(128, activation='relu')(z)\n",
    "    z = Dropout(0.3)(z)\n",
    "    output = Dense(len(list(unique_colors)), activation='sigmoid')(z)\n",
    "\n",
    "    model = Model(inputs=[cnn_input, lstm_input], outputs=[output])\n",
    "    adam = Adam(lr=0.001, decay=1e-5)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "reflected-pollution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:44:19.219952Z",
     "start_time": "2021-03-23T15:44:17.379166Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 115 3\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 75, 115, 3)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 73, 113, 32)  896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 36, 56, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 34, 54, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 27, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 25, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2, 300)       30932700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 12, 128)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2, 300)       0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 10, 128)   147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 2, 64)        93440       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 5, 128)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 64)        0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1280)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           33024       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1280)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          655872      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 18)           1170        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 530)          0           dense_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          135936      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 37)           4773        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,130,643\n",
      "Trainable params: 1,197,943\n",
      "Non-trainable params: 30,932,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = compile_model(word2vec_embedding_matrix)\n",
    "word2vec_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cognitive-mustang",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:44:19.564077Z",
     "start_time": "2021-03-23T15:44:19.220951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-3ddb5783196b>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:582 standardize_input_data\n        str(data_shape))\n\n    ValueError: Error when checking input: expected input_1 to have shape (2,) but got array with shape (1,)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3ddb5783196b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     validation_data=gen_test)\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m       \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shuffle\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mstandardize_function\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m    682\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 684\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m       return ParallelMapDataset(\n\u001b[1;32m-> 1591\u001b[1;33m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   3924\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3925\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3926\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   3927\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[0;32m   3928\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in converted code:\n\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py:677 map_fn\n        batch_size=None)\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py:2410 _standardize_tensors\n        exception_prefix='input')\n    E:\\Anaconda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py:582 standardize_input_data\n        str(data_shape))\n\n    ValueError: Error when checking input: expected input_1 to have shape (2,) but got array with shape (1,)\n"
     ]
    }
   ],
   "source": [
    "history = word2vec_model.fit_generator(\n",
    "    generator = gen_train,\n",
    "    epochs=20,\n",
    "    validation_data=gen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-turning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-photography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-tuner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-vessel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
